"""
Hugging Face ëª¨ë¸ ë° ê¸°íƒ€ AI ëª¨ë¸ì„ ë¯¸ë¦¬ ë‹¤ìš´ë¡œë“œí•˜ê³  ìºì‹œí•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸.
Dockerfileì—ì„œ ì´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ì—¬ ë¹Œë“œ ì‹œì ì— ëª¨ë¸ì„ ì´ë¯¸ì§€ì— í¬í•¨ì‹œí‚µë‹ˆë‹¤.
"""
import os
import torch
from app.settings import settings
from transformers import AutoTokenizer, AutoModelForCausalLM
from huggingface_hub import login

def huggingface_login():
    """Hugging Face Hubì— í”„ë¡œê·¸ë˜ë§¤í‹±í•˜ê²Œ ë¡œê·¸ì¸í•©ë‹ˆë‹¤."""
    print("ğŸ”„ Hugging Face Hubì— ë¡œê·¸ì¸ ì‹œë„...")
    try:
        token = settings.HUGGING_FACE_HUB_TOKEN
        if not token:
            print("âš ï¸ .env íŒŒì¼ì— HUGGING_FACE_HUB_TOKENì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return False
        login(token=token, add_to_git_credential=False)
        print("âœ… Hugging Face Hub ë¡œê·¸ì¸ ì„±ê³µ!")
        return True
    except Exception as e:
        print(f"âŒ Hugging Face Hub ë¡œê·¸ì¸ ì‹¤íŒ¨: {e}")
        return False

def preload_stt_model():
    """STT (Whisper) ëª¨ë¸ ì‚¬ì „ ë¡œë“œ"""
    print("ğŸ”„ STT ëª¨ë¸ ì‚¬ì „ ë¡œë“œ ì‹œì‘...")
    try:
        from whisper import load_model
        model_name = settings.WHISPER_MODEL or "small"
        load_model(model_name)
        print(f"âœ… STT ëª¨ë¸ '{model_name}' ì‚¬ì „ ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ STT ëª¨ë¸ ì‚¬ì „ ë¡œë“œ ì‹¤íŒ¨: {e}")

def preload_llm_model():
    """LLM (CausalLM) ëª¨ë¸ ì‚¬ì „ ë¡œë“œ"""
    print("ğŸ”„ LLM ëª¨ë¸ ì‚¬ì „ ë¡œë“œ ì‹œì‘...")
    try:
        from transformers import AutoTokenizer, AutoModelForCausalLM
        # settings.pyì—ì„œ ëª¨ë¸ IDë¥¼ ê°€ì ¸ì˜¤ë„ë¡ ìˆ˜ì •
        model_id = settings.LLM_MODEL
        
        # MedGemma ë˜ëŠ” Gemma ê³„ì—´ ëª¨ë¸ì„ ìœ„í•œ íŠ¹ë³„ ì²˜ë¦¬
        if "gemma" in model_id:
            print(f"Gemma ê³„ì—´ ëª¨ë¸ ('{model_id}')ì„ ë¡œë“œí•©ë‹ˆë‹¤.")
            AutoTokenizer.from_pretrained(model_id)
            AutoModelForCausalLM.from_pretrained(
                model_id,
                torch_dtype=torch.bfloat16,
                device_map="auto",
            )
        else:
            # ì¼ë°˜ ëª¨ë¸ ë¡œë“œ
            print(f"ì¼ë°˜ LLM ëª¨ë¸ ('{model_id}')ì„ ë¡œë“œí•©ë‹ˆë‹¤.")
            AutoTokenizer.from_pretrained(model_id, use_fast=False)
            AutoModelForCausalLM.from_pretrained(model_id)
            
        print(f"âœ… LLM ëª¨ë¸ '{model_id}' ì‚¬ì „ ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ LLM ëª¨ë¸ ì‚¬ì „ ë¡œë“œ ì‹¤íŒ¨: {e}")

def preload_tts_model():
    """TTS (MeloTTS) ëª¨ë¸ ì‚¬ì „ ë¡œë“œ"""
    print("ğŸ”„ TTS ëª¨ë¸ ì‚¬ì „ ë¡œë“œ ì‹œì‘...")
    try:
        from MeloTTS.melo.api import TTS
        speed = 1.0
        device = "cuda" if torch.cuda.is_available() else "cpu"
        
        # ëª¨ë¸ ê²½ë¡œ ì„¤ì •
        model_path = os.path.join(settings.CHECKPOINTS_DIR, settings.TTS_MODEL_VERSION)
        
        # ëª¨ë¸ ë¡œë“œ (MeloTTSëŠ” ë‚´ë¶€ì ìœ¼ë¡œ í•„ìš”í•œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œ í•¨)
        TTS(language=settings.TTS_LANGUAGE, device=device, ckpt_path=model_path)
        print(f"âœ… TTS ëª¨ë¸ '{settings.TTS_MODEL_VERSION}' ì‚¬ì „ ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ TTS ëª¨ë¸ ì‚¬ì „ ë¡œë“œ ì‹¤íŒ¨: {e}")


def preload_embedding_model():
    """VectorDBìš© ì„ë² ë”© ëª¨ë¸ ì‚¬ì „ ë¡œë“œ"""
    print("ğŸ”„ ì„ë² ë”© ëª¨ë¸ ì‚¬ì „ ë¡œë“œ ì‹œì‘...")
    try:
        from sentence_transformers import SentenceTransformer
        model_name = settings.EMBEDDING_MODEL
        SentenceTransformer(model_name)
        print(f"âœ… ì„ë² ë”© ëª¨ë¸ '{model_name}' ì‚¬ì „ ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ì„ë² ë”© ëª¨ë¸ ì‚¬ì „ ë¡œë“œ ì‹¤íŒ¨: {e}")


if __name__ == "__main__":
    print("ğŸš€ AI ëª¨ë¸ ì‚¬ì „ ë¡œë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    # Hugging Face ë¡œê·¸ì¸ ë¨¼ì € ìˆ˜í–‰
    if not huggingface_login():
        print("ğŸ›‘ Hugging Face ë¡œê·¸ì¸ì´ í•„ìš”í•˜ë¯€ë¡œ ëª¨ë¸ ë¡œë“œë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
    else:
        # settings.pyì˜ ê¸°ë³¸ ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ ë¡œë“œ
        # Docker ë¹Œë“œ í™˜ê²½ì—ì„œëŠ” í™˜ê²½ ë³€ìˆ˜ê°€ ì—†ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
        
        preload_stt_model()
        preload_llm_model()
        # preload_tts_model() # TTSëŠ” ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ë¬¸ì œë¡œ ë¹Œë“œ ì‹œ ì‹¤í–‰ì´ ë³µì¡í•  ìˆ˜ ìˆì–´ ì¼ë‹¨ ì œì™¸
        preload_embedding_model()
        
        print("ğŸ‰ ëª¨ë“  AI ëª¨ë¸ ì‚¬ì „ ë¡œë“œë¥¼ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
