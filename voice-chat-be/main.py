# main.py - FastAPI ë°±ì—”ë“œ ì„œë²„
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
import asyncio
import json
import base64
import numpy as np
import whisper
from TTS.api import TTS
import io
import soundfile as sf
import torch
import librosa

app = FastAPI(title="ì‹¤ì‹œê°„ ìŒì„± ëŒ€í™” ì„œë¹„ìŠ¤")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ ì´ˆê¸°í™”
whisper_model = whisper.load_model("base")  # OpenAI Whisper
tts_model = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device='cuda')  # Coqui TTS

class ConnectionManager:
    def __init__(self):
        self.active_connections: list[WebSocket] = []
    
    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)
    
    def disconnect(self, websocket: WebSocket):
        self.active_connections.remove(websocket)
    
    async def send_message(self, message: str, websocket: WebSocket):
        await websocket.send_text(message)

manager = ConnectionManager()

@app.get("/ping")
async def ping():
    return "pong"

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await manager.connect(websocket)
    try:
        while True:
            # í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° ìŒì„± ë°ì´í„° ìˆ˜ì‹ 
            print('ì‹œì‘')
            data = await websocket.receive_text()
            message = json.loads(data)
            
            if message["type"] == "audio":
                # Base64 ìŒì„± ë°ì´í„° ë””ì½”ë”©
                audio_data = base64.b64decode(message["data"])
                print("[ìˆ˜ì‹ ] : ì˜¤ë””ì˜¤ ê¸¸ì´", len(audio_data))
                # STT ì²˜ë¦¬ (Whisper)
                text = await process_speech_to_text(audio_data)
                print(text)
                if text:
                    # LLM ì²˜ë¦¬
                    reply = await process_llm_response(text)
                    # TTS ì²˜ë¦¬ (Coqui TTS)
                    audio_response = await process_text_to_speech(reply)
                    
                    # ì‘ë‹µ ì „ì†¡
                    response = {
                        "type": "response",
                        "text": reply,
                        "audio": base64.b64encode(audio_response).decode()
                    }
                    await manager.send_message(json.dumps(response), websocket)
                    
    except WebSocketDisconnect:
        manager.disconnect(websocket)


# Whisper ì „ì²˜ë¦¬ ë° STT
async def process_speech_to_text(audio_data: bytes) -> str:
    try:
        with io.BytesIO(audio_data) as f:
            wav_np, sr = sf.read(f, dtype='float32')

        if wav_np.ndim > 1:
            wav_np = np.mean(wav_np, axis=1)  # Stereo â†’ Mono

        if sr != 16000:
            wav_np = librosa.resample(wav_np, orig_sr=sr, target_sr=16000)
            sr = 16000

        # WhisperëŠ” float32 PCM np.array ì…ë ¥ ê¸°ëŒ€
        audio_np = np.ascontiguousarray(wav_np, dtype=np.float32).copy()

        # NaN ê²€ì‚¬
        if np.isnan(audio_np).any():
            print("â—NaN í¬í•¨ëœ ì˜¤ë””ì˜¤")
            return ""

        result = whisper_model.transcribe(audio_np)
        return result.get("text", "")
    except Exception as e:
        print(f"âŒ STT ì˜¤ë¥˜: {e}")
        return ""


# Hugging Face LLM ì‚¬ìš©
async def process_llm_response(user_input: str) -> str:
    try:
        from transformers import pipeline
        generator = pipeline("text-generation", model="mistralai/Mistral-7B-Instruct-v0.1", device=0 if torch.cuda.is_available() else -1)
        outputs = generator(user_input, max_length=100, do_sample=True)
        return outputs[0]["generated_text"]
    except Exception as e:
        print(f"âŒ LLM ì˜¤ë¥˜: {e}")
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

# TTS ì²˜ë¦¬
async def process_text_to_speech(text: str) -> bytes:
    try:
        audio = tts_model.tts(text)  # numpy float32
        audio_bytes = (audio * 32767).astype(np.int16).tobytes()
        return audio_bytes
    except Exception as e:
        print(f"âŒ TTS ì˜¤ë¥˜: {e}")
        return b""

if __name__ == "__main__":
    import uvicorn
    print("ğŸš€ FastAPI ì„œë²„ ì‹œì‘ ì¤‘...")
    uvicorn.run(app, host="0.0.0.0", port=8000)